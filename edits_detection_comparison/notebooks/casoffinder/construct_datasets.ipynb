{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct edits datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant data variables\n",
    "BASEDIR = \"/data/\"\n",
    "CASOFFINDER = os.path.join(BASEDIR, \"/path/to/casoffinder\")\n",
    "EDITSDIR = os.path.join(\n",
    "    BASEDIR, \n",
    "    \"/path/to/edits/folder/\",\n",
    ")\n",
    "REPORTSDIR = os.path.join(\n",
    "    BASEDIR, \n",
    "    \"/path/to/reports/folder/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to create the reports\n",
    "def casoffinder_report(guide: str) -> str:\n",
    "    guide = guide.replace(\"Site3\", \"3\").replace(\"Site4\", \"4\")  # rename guide \n",
    "    return f\"casoffinder.{guide}.txt.out\"\n",
    "\n",
    "def recover_site(\n",
    "    chrom: str, pos: int, strand: str, upstream: bool, downstream: bool\n",
    ") -> str:\n",
    "    center = pos + 17 if strand == \"+\" else pos + 6\n",
    "    start = center - 10\n",
    "    stop = center + 10\n",
    "    if upstream:\n",
    "        return f\"{chrom}:{start - 1 - 20}-{start - 1}\"\n",
    "    elif downstream:\n",
    "        return f\"{chrom}:{stop + 1}-{stop + 1 + 20}\"\n",
    "    return f\"{chrom}:{start}-{stop}\"\n",
    "\n",
    "def read_vcf(vcf: str, tool: str) -> List[List[Any]]:\n",
    "    if tool == \"mutect2\":  # MUTECT2\n",
    "        with open(vcf, mode=\"r\") as infile:\n",
    "            variants = [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "    elif tool == \"strelka\":  # STRELKA \n",
    "        with open(vcf.replace(\".vcf\", \"_somatic.snvs.vcf\"), mode=\"r\") as infile:  # SNVs\n",
    "            variants = [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "        with open(vcf.replace(\".vcf\", \"_somatic.indels.vcf\"), mode=\"r\") as infile:  # indels\n",
    "            variants = variants + [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "    elif tool == \"varscan\":  # VARSCAN \n",
    "        with open(vcf.replace(\".vcf\", \".snp.vcf\"), mode=\"r\") as infile:  # SNVs\n",
    "            variants = [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "        with open(vcf.replace(\".vcf\", \".indel.vcf\"), mode=\"r\") as infile:  # indels\n",
    "            variants = variants + [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "    return variants\n",
    "\n",
    "def read_edits(edits: pd.Series, site: str) -> pd.DataFrame:\n",
    "    data = pd.DataFrame(edits)  # read called edits\n",
    "    if data.empty:\n",
    "        return pd.DataFrame()  # return empty DataFrame\n",
    "    data = data.iloc[:, [0, 1, 3, 4]]  # keep chrom, pos, ref, alt\n",
    "    data.columns = [\"CHROM\", \"EDITPOS\", \"REF\", \"ALT\"]\n",
    "    data[\"SITE\"] = site  # add site name (used in later join)\n",
    "    return data\n",
    "\n",
    "def edits_df(edits: pd.Series, offtargets: pd.DataFrame) -> pd.DataFrame: \n",
    "    edits_df = pd.concat(\n",
    "        [read_edits(edits.loc[i], offtargets.SITE[i]) for i in range(edits.shape[0])]\n",
    "    )\n",
    "    if edits_df.empty:\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"GUIDE\", \"CHR\", \"POS\", \"TARGET\", \"STRAND\", \"MM\", \"SITE\", \"EDITPOS\", \"REF\", \"ALT\", \"EDITTYPE\"\n",
    "            ]\n",
    "        )\n",
    "    edits_df = offtargets.merge(edits_df, on=\"SITE\")  # merge offtargets and edits\n",
    "    edits_df.drop([\"CHROM\"], axis=1, inplace=True)  # remove redundant chrom column\n",
    "    edits_df.reset_index(drop=True, inplace=True)\n",
    "    return edits_df\n",
    "\n",
    "def etype(allele_ref: str, allele_alt: str) -> str:\n",
    "    if len(allele_ref) < len(allele_alt):  # insertion\n",
    "        return \"insertion\"\n",
    "    elif len(allele_ref) > len(allele_alt):  # deletion\n",
    "        return \"deletion\"\n",
    "    return \"snv\"  # base-case SNV\n",
    "\n",
    "def assign_type(ref: str, alt: str) -> str:\n",
    "    if \",\" in alt:  # polyploid alternative allele\n",
    "        return \"-\".join(list(set([etype(ref, aa) for aa in alt.split(\",\")])))\n",
    "    return etype(ref, alt)  # regular alternative allele\n",
    "\n",
    "def construct_report(\n",
    "    guide: str, \n",
    "    tool: str, \n",
    "    cell_type: str,\n",
    "    upstream: Optional[bool] = False, \n",
    "    downstream: Optional[bool] = False,\n",
    ") -> pd.DataFrame:\n",
    "    assert (upstream + downstream == 0) or (upstream + downstream == 1)    \n",
    "    sys.stderr.write(\n",
    "        f\"Constructing report for edits called by {tool} on cell type \"\n",
    "        f\"{cell_type} and guide {guide}...\\n\"\n",
    "    )\n",
    "    offtargets = pd.read_csv(\n",
    "        os.path.join(CASOFFINDER, casoffinder_report(guide)), sep=\"\\t\", header=None\n",
    "    )\n",
    "    # rename casoffinder report columns and sort sites by mismatches number\n",
    "    offtargets.columns = [\"GUIDE\", \"CHR\", \"POS\", \"TARGET\", \"STRAND\", \"MM\"]\n",
    "    offtargets.sort_values(\"MM\", ascending=True, inplace=True)\n",
    "    offtargets[\"SITE\"] = offtargets.apply(\n",
    "        lambda x: recover_site(x[1], x[2], x[4], upstream, downstream), axis=1\n",
    "    )  # recover edits sites (used for later join)\n",
    "    # recover edits called on each off-target site\n",
    "    tqdm.pandas()  # track apply() progress\n",
    "    edits = offtargets.progress_apply(\n",
    "        lambda x: read_vcf(\n",
    "            os.path.join(EDITSDIR, tool, cell_type, guide, f\"{x[6]}.vcf\"), tool\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "    edits_dataset = edits_df(edits, offtargets)  # construct the edits dataset\n",
    "    if not edits_dataset.empty:\n",
    "        edits_dataset[\"EDITTYPE\"] = edits_dataset.apply(\n",
    "            lambda x: assign_type(x[8], x[9]), axis=1\n",
    "        )  # assign edits type\n",
    "    return edits_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUIDES = [\"EMX1\", \"HEKSite4\", \"RNF2\", \"VEGFASite3\"]\n",
    "CELLTYPES = [\"GM12878\", \"K562\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing report for edits called by mutect2 on cell type GM12878 and guide EMX1...\n",
      "100%|██████████| 293/293 [00:00<00:00, 1255.49it/s]\n",
      "Constructing report for edits called by mutect2 on cell type GM12878 and guide HEKSite4...\n",
      "100%|██████████| 832/832 [00:00<00:00, 1265.66it/s]\n",
      "Constructing report for edits called by mutect2 on cell type GM12878 and guide RNF2...\n",
      "100%|██████████| 7/7 [00:00<00:00, 1112.13it/s]\n",
      "Constructing report for edits called by mutect2 on cell type GM12878 and guide VEGFASite3...\n",
      "100%|██████████| 6509/6509 [00:05<00:00, 1184.81it/s]\n",
      "Constructing report for edits called by mutect2 on cell type K562 and guide EMX1...\n",
      "100%|██████████| 293/293 [00:00<00:00, 1319.75it/s]\n",
      "Constructing report for edits called by mutect2 on cell type K562 and guide HEKSite4...\n",
      "100%|██████████| 832/832 [00:00<00:00, 1277.82it/s]\n",
      "Constructing report for edits called by mutect2 on cell type K562 and guide RNF2...\n",
      "100%|██████████| 7/7 [00:00<00:00, 1026.47it/s]\n",
      "Constructing report for edits called by mutect2 on cell type K562 and guide VEGFASite3...\n",
      "100%|██████████| 6509/6509 [00:05<00:00, 1143.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# GATK MUTECT2\n",
    "tool = \"mutect2\"\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        # if constructing reports for upstream or downstream regions, set the \n",
    "        # appropriate flags in construct_reports()\n",
    "        edits = construct_report(guide, tool, cell_type, upstream=True)  \n",
    "        # store the edits dataset\n",
    "        outdir = os.path.join(REPORTSDIR, tool)\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        edits.to_csv(\n",
    "            os.path.join(outdir, f\"{guide}_{cell_type}.txt\"), index=False, sep=\"\\t\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing report for edits called by strelka on cell type GM12878 and guide EMX1...\n",
      "100%|██████████| 293/293 [00:05<00:00, 54.38it/s]\n",
      "Constructing report for edits called by strelka on cell type GM12878 and guide HEKSite4...\n",
      "100%|██████████| 832/832 [00:13<00:00, 61.74it/s]\n",
      "Constructing report for edits called by strelka on cell type GM12878 and guide RNF2...\n",
      "100%|██████████| 7/7 [00:00<00:00, 57.18it/s]\n",
      "Constructing report for edits called by strelka on cell type GM12878 and guide VEGFASite3...\n",
      "100%|██████████| 6509/6509 [01:46<00:00, 61.04it/s]\n",
      "Constructing report for edits called by strelka on cell type K562 and guide EMX1...\n",
      "100%|██████████| 293/293 [00:04<00:00, 60.04it/s]\n",
      "Constructing report for edits called by strelka on cell type K562 and guide HEKSite4...\n",
      "100%|██████████| 832/832 [00:14<00:00, 58.77it/s]\n",
      "Constructing report for edits called by strelka on cell type K562 and guide RNF2...\n",
      "100%|██████████| 7/7 [00:00<00:00, 35.54it/s]\n",
      "Constructing report for edits called by strelka on cell type K562 and guide VEGFASite3...\n",
      "100%|██████████| 6509/6509 [01:46<00:00, 60.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# STRELKA\n",
    "tool = \"strelka\"\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        # if constructing reports for upstream or downstream regions, set the \n",
    "        # appropriate flags in construct_reports()\n",
    "        edits = construct_report(guide, tool, cell_type, upstream=True)\n",
    "        # store the edits dataset\n",
    "        outdir = os.path.join(REPORTSDIR, tool)\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        edits.to_csv(\n",
    "            os.path.join(outdir, f\"{guide}_{cell_type}.txt\"), index=False, sep=\"\\t\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing report for edits called by varscan on cell type GM12878 and guide EMX1...\n",
      "100%|██████████| 293/293 [00:00<00:00, 309.36it/s]\n",
      "Constructing report for edits called by varscan on cell type GM12878 and guide HEKSite4...\n",
      "100%|██████████| 832/832 [00:01<00:00, 436.05it/s]\n",
      "Constructing report for edits called by varscan on cell type GM12878 and guide RNF2...\n",
      "100%|██████████| 7/7 [00:00<00:00, 415.23it/s]\n",
      "Constructing report for edits called by varscan on cell type GM12878 and guide VEGFASite3...\n",
      "100%|██████████| 6509/6509 [00:13<00:00, 465.25it/s]\n",
      "Constructing report for edits called by varscan on cell type K562 and guide EMX1...\n",
      "100%|██████████| 293/293 [00:00<00:00, 393.99it/s]\n",
      "Constructing report for edits called by varscan on cell type K562 and guide HEKSite4...\n",
      "100%|██████████| 832/832 [00:02<00:00, 384.21it/s]\n",
      "Constructing report for edits called by varscan on cell type K562 and guide RNF2...\n",
      "100%|██████████| 7/7 [00:00<00:00, 378.74it/s]\n",
      "Constructing report for edits called by varscan on cell type K562 and guide VEGFASite3...\n",
      "100%|██████████| 6509/6509 [00:13<00:00, 467.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# VARSCAN\n",
    "tool = \"varscan\"\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        # if constructing reports for upstream or downstream regions, set the \n",
    "        # appropriate flags in construct_reports()\n",
    "        edits = construct_report(guide, tool, cell_type, upstream=True)\n",
    "        # store the edits dataset\n",
    "        outdir = os.path.join(REPORTSDIR, tool)\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        edits.to_csv(\n",
    "            os.path.join(outdir, f\"{guide}_{cell_type}.txt\"), index=False, sep=\"\\t\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
