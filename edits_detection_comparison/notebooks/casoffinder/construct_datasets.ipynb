{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct edits datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant data variables\n",
    "BASEDIR = \"/path/to/data\"\n",
    "CASOFFINDER = os.path.join(BASEDIR, \"/path/to/casoffinder/targets\")\n",
    "EDITSDIR = os.path.join(BASEDIR, \"/paths/to/edits/vcf\")\n",
    "REPORTSDIR = os.path.join(BASEDIR, \"/path/to/reports/folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to create the reports\n",
    "def casoffinder_report(guide: str) -> str:\n",
    "    guide = guide.replace(\"Site3\", \"3\").replace(\"Site4\", \"4\")  # rename guide \n",
    "    return f\"casoffinder.{guide}.txt.out\"\n",
    "\n",
    "def recover_site(chrom: str, pos: int, strand: str) -> str:\n",
    "    center = pos + 17 if strand == \"+\" else pos + 6\n",
    "    start = center - 10\n",
    "    stop = center + 10\n",
    "    return f\"{chrom}:{start}-{stop}\"\n",
    "\n",
    "def read_vcf(vcf: str, tool: str) -> List[List[Any]]:\n",
    "    if tool == \"mutect2\":  # MUTECT2\n",
    "        with open(vcf, mode=\"r\") as infile:\n",
    "            variants = [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "    elif tool == \"strelka\":  # STRELKA\n",
    "        with open(vcf.replace(\".vcf\", \"_somatic.snvs.vcf\"), mode=\"r\") as infile:  # SNVs\n",
    "            variants = [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "        with open(vcf.replace(\".vcf\", \"_somatic.indels.vcf\"), mode=\"r\") as infile:  # indels\n",
    "            variants += [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "    elif tool == \"varscan\":  # VARSCAN\n",
    "        with open(vcf.replace(\".vcf\", \".snp.vcf\"), mode=\"r\") as infile:  # SNVs\n",
    "            variants = [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "        with open(vcf.replace(\".vcf\", \".indel.vcf\"), mode=\"r\") as infile:  # indels\n",
    "            variants += [\n",
    "                line.strip().split() for line in infile if not line.startswith(\"#\")\n",
    "            ]\n",
    "    return variants\n",
    "\n",
    "def read_edits(edits: pd.Series, site: str) -> pd.DataFrame:\n",
    "    data = pd.DataFrame(edits)  # read called edits\n",
    "    if data.empty:\n",
    "        return pd.DataFrame()  # return empty DataFrame\n",
    "    data = data.iloc[:, [0, 1, 3, 4]]  # keep chrom, pos, ref, alt\n",
    "    data.columns = [\"CHROM\", \"EDITPOS\", \"REF\", \"ALT\"]\n",
    "    data[\"SITE\"] = site  # add site name (used in later join)\n",
    "    return data\n",
    "\n",
    "def edits_df(edits: pd.Series, offtargets: pd.DataFrame) -> pd.DataFrame: \n",
    "    edits_df = pd.concat(\n",
    "        [read_edits(edits.loc[i], offtargets.SITE[i]) for i in range(edits.shape[0])]\n",
    "    )\n",
    "    edits_df = offtargets.merge(edits_df, on=\"SITE\")  # merge offtargets and edits\n",
    "    edits_df.drop([\"CHROM\"], axis=1, inplace=True)  # remove redundant chrom column\n",
    "    edits_df.reset_index(drop=True, inplace=True)\n",
    "    return edits_df\n",
    "\n",
    "def etype(allele_ref: str, allele_alt: str) -> str:\n",
    "    if len(allele_ref) < len(allele_alt):  # insertion\n",
    "        return \"insertion\"\n",
    "    elif len(allele_ref) > len(allele_alt):  # deletion\n",
    "        return \"deletion\"\n",
    "    return \"snv\"  # base-case SNV\n",
    "\n",
    "def assign_type(ref: str, alt: str) -> str:\n",
    "    if \",\" in alt:  # polyploid alternative allele\n",
    "        return \"-\".join(list({etype(ref, aa) for aa in alt.split(\",\")}))\n",
    "    return etype(ref, alt)  # regular alternative allele\n",
    "\n",
    "def construct_report(guide: str, tool: str, cell_type: str) -> pd.DataFrame:\n",
    "    sys.stderr.write(\n",
    "        f\"Constructing report for edits called by {tool} on cell type \"\n",
    "        f\"{cell_type} and guide {guide}...\\n\"\n",
    "    )\n",
    "    offtargets = pd.read_csv(\n",
    "        os.path.join(CASOFFINDER, casoffinder_report(guide)), sep=\"\\t\", header=None\n",
    "    )\n",
    "    # rename casoffinder report columns and sort sites by mismatches number\n",
    "    offtargets.columns = [\"GUIDE\", \"CHR\", \"POS\", \"TARGET\", \"STRAND\", \"MM\"]\n",
    "    offtargets.sort_values(\"MM\", ascending=True, inplace=True)\n",
    "    offtargets[\"SITE\"] = offtargets.apply(\n",
    "        lambda x: recover_site(x[1], x[2], x[4]), axis=1\n",
    "    )  # recover edits sites (used for later join)\n",
    "    # recover edits called on each off-target site\n",
    "    tqdm.pandas()  # track apply() progress\n",
    "    edits = offtargets.progress_apply(\n",
    "        lambda x: read_vcf(\n",
    "            os.path.join(EDITSDIR, tool, cell_type, guide, f\"{x[6]}.vcf\"), tool\n",
    "        ), \n",
    "        axis=1\n",
    "    )\n",
    "    edits_dataset = edits_df(edits, offtargets)  # construct the edits dataset\n",
    "    edits_dataset[\"EDITTYPE\"] = edits_dataset.apply(\n",
    "        lambda x: assign_type(x[8], x[9]), axis=1\n",
    "    )  # assign edits type\n",
    "    return edits_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUIDES = [\"EMX1\", \"HEKSite4\", \"RNF2\", \"VEGFASite3\"]\n",
    "CELLTYPES = [\"GM12878\", \"K562\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GATK MUTECT2\n",
    "tool = \"mutect2\"\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        edits = construct_report(guide, tool, cell_type)\n",
    "        # store the edits dataset\n",
    "        outdir = os.path.join(REPORTSDIR, tool)\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        edits.to_csv(\n",
    "            os.path.join(outdir, f\"{guide}_{cell_type}.txt\"), index=False, sep=\"\\t\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRELKA\n",
    "tool = \"strelka\"\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        edits = construct_report(guide, tool, cell_type)\n",
    "        # store the edits dataset\n",
    "        outdir = os.path.join(REPORTSDIR, tool)\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        edits.to_csv(\n",
    "            os.path.join(outdir, f\"{guide}_{cell_type}.txt\"), index=False, sep=\"\\t\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARSCAN\n",
    "tool = \"varscan\"\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        edits = construct_report(guide, tool, cell_type)\n",
    "        # store the edits dataset\n",
    "        outdir = os.path.join(REPORTSDIR, tool)\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        edits.to_csv(\n",
    "            os.path.join(outdir, f\"{guide}_{cell_type}.txt\"), index=False, sep=\"\\t\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
