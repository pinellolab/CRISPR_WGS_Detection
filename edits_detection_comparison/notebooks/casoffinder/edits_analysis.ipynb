{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edits analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pybedtools\n",
    "import pysam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant data variables\n",
    "BASEDIR = \"/data/\"\n",
    "REPORTSDIR = os.path.join(\n",
    "    BASEDIR, \n",
    "    \"/path/to/reports/folder\",\n",
    ")\n",
    "NA12878DIR = os.path.join(\n",
    "    BASEDIR,\n",
    "    \"/path/to/NA12878\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of edits called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUIDES = [\"EMX1\", \"HEKSite4\", \"RNF2\", \"VEGFASite3\"]\n",
    "CELLTYPES = [\"GM12878\", \"K562\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of edits called by each tool on each dataset\n",
    "TOOLS = [\"mutect2\", \"strelka\", \"varscan\"]\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        data = []\n",
    "        for tool in TOOLS:\n",
    "            edits = pd.read_csv(\n",
    "                os.path.join(REPORTSDIR, tool, f\"{guide}_{cell_type}.txt\"), sep=\"\\t\"\n",
    "            )\n",
    "            data.append(\n",
    "                [\n",
    "                    tool.upper(), \n",
    "                    edits[edits.EDITTYPE == \"snv\"].shape[0], \n",
    "                    edits[edits.EDITTYPE == \"insertion\"].shape[0],\n",
    "                    edits[edits.EDITTYPE == \"deletion\"].shape[0],\n",
    "                    edits[edits.EDITTYPE.str.contains(\"-\")].shape[0],\n",
    "                ]\n",
    "            )\n",
    "        f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        data = pd.DataFrame(\n",
    "            data, columns=[\"TOOL\", \"SNV\", \"INSERTION\", \"DELETION\", \"POLYPLOID\"]\n",
    "        )\n",
    "        data.plot(x=\"TOOL\", kind=\"bar\", stacked=False, ax=ax)\n",
    "        ax.set_xlabel(\"Variant Calling Tool\", size=14)\n",
    "        ax.set_ylabel(\"Counts\", size=14)\n",
    "        ax.tick_params(axis=\"both\", labelsize=12)\n",
    "        ax.set_title(f\"Edit type ({guide}-{cell_type})\", size=16)\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of edits by mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for guide in GUIDES:\n",
    "    for cell_type in CELLTYPES:\n",
    "        for tool in TOOLS:\n",
    "            edits = pd.read_csv(\n",
    "                os.path.join(\n",
    "                    REPORTSDIR, tool, f\"{guide}_{cell_type}.txt\"\n",
    "                ), \n",
    "                sep=\"\\t\"\n",
    "            )\n",
    "            data = []\n",
    "            for mm in range(5):\n",
    "                data.append(\n",
    "                    [\n",
    "                        mm, \n",
    "                        edits[(edits.EDITTYPE == \"snv\") & (edits.MM == mm)].shape[0], \n",
    "                        edits[(edits.EDITTYPE == \"insertion\") & (edits.MM == mm)].shape[0],\n",
    "                        edits[(edits.EDITTYPE == \"deletion\") & (edits.MM == mm)].shape[0],\n",
    "                        edits[(edits.EDITTYPE.str.contains(\"-\")) & (edits.MM == mm)].shape[0],\n",
    "                    ]\n",
    "                )\n",
    "            f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "            data = pd.DataFrame(\n",
    "                data, columns=[\"MM\", \"SNV\", \"INSERTION\", \"DELETION\", \"POLYPLOID\"]\n",
    "            )\n",
    "            data.plot(x=\"MM\", kind=\"bar\", stacked=False, ax=ax)\n",
    "            ax.set_xlabel(\"Mismatches\", size=14)\n",
    "            ax.set_ylabel(\"Counts\", size=14)\n",
    "            ax.tick_params(axis=\"both\", labelsize=12, rotation=0)\n",
    "            ax.set_title(f\"Edit type ({guide}-{cell_type}-{tool})\", size=16)\n",
    "            plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edits call agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        variants = []\n",
    "        for tool in TOOLS:\n",
    "            edits = pd.read_csv(\n",
    "                os.path.join(REPORTSDIR, tool, f\"{guide}_{cell_type}.txt\"), sep=\"\\t\"\n",
    "            )\n",
    "            variants.append(set(edits.apply(lambda x: f\"{x[1]}:{x[7]}\", axis=1)))\n",
    "        f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        venn3(variants, set_labels=[\"MUTECT2\", \"STRELKA\", \"VARSCAN\"])\n",
    "        venn3_circles(variants)\n",
    "        ax.set_title(f\"Edits called ({guide}-{cell_type})\", size=16)\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-confidence SNPs called as edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMS = [f\"chr{i}\" for i in range(1, 23)]\n",
    "\n",
    "# find number of edits that are high confidence variants\n",
    "def fetch_snps(vcf: pysam.TabixFile, chrom: str, pos: int) -> List[str]:\n",
    "    if chrom not in CHROMS:  # skip sex chroms\n",
    "        return []\n",
    "    return list(vcf.fetch(chrom, pos - 1, pos))\n",
    "\n",
    "def high_confidence_snps(\n",
    "    edits: pd.DataFrame, vcf: pysam.TabixFile\n",
    ") -> Tuple[List[List[str]], pd.DataFrame]:\n",
    "    hc_snps = list(edits.apply(lambda x: fetch_snps(vcf, x[1], x[7]), axis=1))\n",
    "    return hc_snps, edits.iloc[[i for i, snp in enumerate(hc_snps) if bool(snp)], :]\n",
    "\n",
    "def plot_hc_snps(\n",
    "    hcsnps: List[List[str]], hcsnpsdf: pd.DataFrame, guide: str, cell_type: str\n",
    ") -> None:\n",
    "    counts = [len(hcsnps) - hcsnpsdf.shape[0], hcsnpsdf.shape[0]]\n",
    "    labels = [\"Edits\", \"HC SNPs\"]\n",
    "    f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    ax.bar(labels, counts, width=.2, color=\"#0093D3\")\n",
    "    ax.set_ylabel(\"Counts\", size=14)\n",
    "    ax.tick_params(axis=\"both\", labelsize=12)\n",
    "    ax.set_title(\n",
    "        f\"Number of HC SNP called as edits ({guide}-{cell_type})\", size=16\n",
    "    )\n",
    "    plt.savefig(os.path.join(\"figures\", f\"hc_varscan_{guide.lower()}_{cell_type.lower()}.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUTECT2\n",
    "tool = \"mutect2\"\n",
    "na12878vcf = pysam.Tabixfile(\n",
    "    os.path.join(NA12878DIR, \"HG001_GRCh38_1_22_v4.2.1_annotated.vcf.gz\")\n",
    ")  # HC SNPs VCF\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        edits = pd.read_csv(\n",
    "            os.path.join(REPORTSDIR, tool, f\"{guide}_{cell_type}.txt\"), sep=\"\\t\"\n",
    "        )\n",
    "        hcsnps, hcsnpsdf = high_confidence_snps(edits, na12878vcf)\n",
    "        # store HC SNPs called as edits\n",
    "        outdir = os.path.join(REPORTSDIR, tool)\n",
    "        if not os.path.exists:\n",
    "            os.mkdir(outdir)\n",
    "        hcsnpsdf.to_csv(\n",
    "            os.path.join(outdir, f\"{guide}_{cell_type}_hc.txt\"), sep=\"\\t\", index=False\n",
    "        )\n",
    "        plot_hc_snps(hcsnps, hcsnpsdf, guide, cell_type)  # plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRELKA\n",
    "tool = \"strelka\"\n",
    "na12878vcf = pysam.Tabixfile(\n",
    "    os.path.join(NA12878DIR, \"HG001_GRCh38_1_22_v4.2.1_annotated.vcf.gz\")\n",
    ")  # HC SNPs VCF\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        edits = pd.read_csv(\n",
    "            os.path.join(REPORTSDIR, tool, f\"{guide}_{cell_type}.txt\"), sep=\"\\t\"\n",
    "        )\n",
    "        hcsnps, hcsnpsdf = high_confidence_snps(edits, na12878vcf)\n",
    "        # store HC SNPs called as edits\n",
    "        outdir = os.path.join(REPORTSDIR, tool)\n",
    "        if not os.path.exists:\n",
    "            os.mkdir(outdir)\n",
    "        hcsnpsdf.to_csv(\n",
    "            os.path.join(outdir, f\"{guide}_{cell_type}_hc.txt\"), sep=\"\\t\", index=False\n",
    "        )\n",
    "        plot_hc_snps(hcsnps, hcsnpsdf, guide, cell_type)  # plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARSCAN\n",
    "tool = \"varscan\"\n",
    "na12878vcf = pysam.Tabixfile(\n",
    "    os.path.join(NA12878DIR, \"HG001_GRCh38_1_22_v4.2.1_annotated.vcf.gz\")\n",
    ")  # HC SNPs VCF\n",
    "for cell_type in CELLTYPES:\n",
    "    for guide in GUIDES:\n",
    "        edits = pd.read_csv(\n",
    "            os.path.join(REPORTSDIR, tool, f\"{guide}_{cell_type}.txt\"), sep=\"\\t\"\n",
    "        )\n",
    "        hcsnps, hcsnpsdf = high_confidence_snps(edits, na12878vcf)\n",
    "        # store HC SNPs called as edits\n",
    "        outdir = os.path.join(REPORTSDIR, tool)\n",
    "        if not os.path.exists:\n",
    "            os.mkdir(outdir)\n",
    "        hcsnpsdf.to_csv(\n",
    "            os.path.join(outdir, f\"{guide}_{cell_type}_hc.txt\"), sep=\"\\t\", index=False\n",
    "        )\n",
    "        plot_hc_snps(hcsnps, hcsnpsdf, guide, cell_type)  # plot histogram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HC SNPs and edits agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute agreement between edits and high-confidence SNPs\n",
    "CHROMS = [f\"chr{i}\" for i in range(1, 23)]\n",
    "def compare_alleles(alte: str, alts: str) -> int:\n",
    "    alte = alte.split(\",\")  # handle polyploid alleles\n",
    "    if any([aa == alts for aa in alte]):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def hcedits_jaccard(edits: pd.DataFrame, vcf: pysam.TabixFile):\n",
    "    snps = list(edits.apply(lambda x: fetch_snps(vcf, x[1], x[7]), axis=1))\n",
    "    hceditsidxs = [i for i, snp in enumerate(snps) if bool(snp)]\n",
    "    if len(hceditsidxs) == 0:\n",
    "        return np.nan\n",
    "    return (\n",
    "        sum([compare_alleles(edits.iloc[i,9], snps[i][0].split()[4]) for i in hceditsidxs]) / len(hceditsidxs)\n",
    "    )\n",
    "\n",
    "def plot_heatmap(hcedits: pd.DataFrame, tool: str) -> None:\n",
    "    f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    sns.heatmap(hcedits, cmap=\"coolwarm\", annot=True, vmin=0, vmax=1)\n",
    "    ax.set_title(f\"Jaccard distance HC edits - {tool}\", size=16)\n",
    "    ax.set_xlabel(\"Cell type\", size=14)\n",
    "    ax.set_ylabel(\"Guide\", size=14)\n",
    "    ax.tick_params(axis=\"both\", labelsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUTECT2\n",
    "tool = \"mutect2\"\n",
    "na12878vcf = pysam.Tabixfile(\n",
    "    os.path.join(NA12878DIR, \"HG001_GRCh38_1_22_v4.2.1_annotated.vcf.gz\")\n",
    ")  # HC SNPs VCF\n",
    "jaccard_distances = {  # compute Jaccard distances\n",
    "    cell_type: {\n",
    "        guide: hcedits_jaccard(\n",
    "            pd.read_csv(\n",
    "                os.path.join(REPORTSDIR, tool, f\"{guide}_{cell_type}.txt\"),\n",
    "                sep=\"\\t\"\n",
    "            ),\n",
    "            na12878vcf\n",
    "        )\n",
    "        for guide in GUIDES\n",
    "    }\n",
    "    for cell_type in CELLTYPES\n",
    "}\n",
    "plot_heatmap(pd.DataFrame(jaccard_distances), tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRELKA\n",
    "tool = \"strelka\"\n",
    "na12878vcf = pysam.Tabixfile(\n",
    "    os.path.join(NA12878DIR, \"HG001_GRCh38_1_22_v4.2.1_annotated.vcf.gz\")\n",
    ")  # HC SNPs VCF\n",
    "jaccard_distances = {  # compute Jaccard distances\n",
    "    cell_type: {\n",
    "        guide: hcedits_jaccard(\n",
    "            pd.read_csv(\n",
    "                os.path.join(REPORTSDIR, tool, f\"{guide}_{cell_type}.txt\"),\n",
    "                sep=\"\\t\"\n",
    "            ),\n",
    "            na12878vcf\n",
    "        )\n",
    "        for guide in GUIDES\n",
    "    }\n",
    "    for cell_type in CELLTYPES\n",
    "}\n",
    "plot_heatmap(pd.DataFrame(jaccard_distances), tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARSCAN\n",
    "tool = \"varscan\"\n",
    "na12878vcf = pysam.Tabixfile(\n",
    "    os.path.join(NA12878DIR, \"HG001_GRCh38_1_22_v4.2.1_annotated.vcf.gz\")\n",
    ")  # HC SNPs VCF\n",
    "jaccard_distances = {  # compute Jaccard distances\n",
    "    cell_type: {\n",
    "        guide: hcedits_jaccard(\n",
    "            pd.read_csv(\n",
    "                os.path.join(REPORTSDIR, tool, f\"{guide}_{cell_type}.txt\"),\n",
    "                sep=\"\\t\"\n",
    "            ),\n",
    "            na12878vcf\n",
    "        )\n",
    "        for guide in GUIDES\n",
    "    }\n",
    "    for cell_type in CELLTYPES\n",
    "}\n",
    "plot_heatmap(pd.DataFrame(jaccard_distances), tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
