{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build edits datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEDIR = \"/data/pinello/PROJECTS/2017_07_DARPA_SIMULATIONS\"\n",
    "GUIDESEQ = os.path.join(\n",
    "    BASEDIR, \"offtargetDetection/casoffinder/offby6/CRISPRessoWGS/guideseq_anno\"\n",
    ")\n",
    "CIRCLESEQ = os.path.join(BASEDIR, \"offtargetDetection/circleseq/\")\n",
    "EDITS = os.path.join(\n",
    "    BASEDIR, \"wgs/GM12878-Cas9/WGS1000/detectWithOtherTools/manuel_experiments/VCFs\"\n",
    ")\n",
    "REPORTS = os.path.join(\n",
    "    BASEDIR, \"wgs/GM12878-Cas9/WGS1000/detectWithOtherTools/manuel_experiments/reports\"\n",
    ")\n",
    "GUIDES = [\"EMX1\", \"HEKSite4\", \"RNF2\", \"VEGFASite3\"]\n",
    "EXPERIMENTS = [\"circleseq\", \"guideseq\"]\n",
    "CELLTYPES = [\"GM12878\", \"K562\"]\n",
    "PADSIZE = 10000\n",
    "INSERTION = \"insertion\"\n",
    "DELETION = \"deletion\"\n",
    "SNV = \"snv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutect2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mutect2(vcf: str) -> List[List]:\n",
    "    \"\"\" (PRIVATE)\n",
    "    \n",
    "    The function parses the input VCF obtained running Mutect2.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        handle = open(vcf, mode=\"r\")\n",
    "        variants = [\n",
    "            line.strip().split() for line in handle if not line.startswith(\"#\")\n",
    "        ]\n",
    "    except OSError:\n",
    "        raise OSError(f\"An error occurred while parsing {vcf}\")\n",
    "    finally:\n",
    "        handle.close()\n",
    "    return variants\n",
    "\n",
    "\n",
    "def parse_variants(variants: pd.Series, target_sites: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"The function builds a pandas DataFrame storing the input variants.\"\"\"\n",
    "    assert len(variants) == len(target_sites)\n",
    "    vdf = {\n",
    "        \"SITE\": [], \"CHROM\": [], \"POS\": [], \"ID\": [], \"REF\": [], \"ALT\": [], \"FILTER\": []\n",
    "    }\n",
    "    for i, tvariants in enumerate(variants):\n",
    "        if bool(tvariants):  # skip target sites without variants\n",
    "            for v in tvariants:\n",
    "                vdf[\"SITE\"].append(target_sites[i])\n",
    "                vdf[\"CHROM\"].append(v[0])\n",
    "                vdf[\"POS\"].append(v[1])\n",
    "                vdf[\"ID\"].append(v[2])\n",
    "                vdf[\"REF\"].append(v[3])\n",
    "                vdf[\"ALT\"].append(v[4])\n",
    "                vdf[\"FILTER\"].append(v[6])\n",
    "    vdf = pd.DataFrame(vdf)\n",
    "    return vdf\n",
    "\n",
    "\n",
    "def assign_vtype(ref: str, alt: str) -> str:\n",
    "    \"\"\"The function assigns their type (insertion, deletion, or SNV) to each \n",
    "    input variant.\n",
    "    \"\"\"\n",
    "    if \",\" in alt:  # polyploid alternative allele\n",
    "        vtypes = []\n",
    "        for aa in alt.split(\",\"):\n",
    "            if len(ref) < len(aa):\n",
    "                vtypes.append(INSERTION)\n",
    "            elif len(aa) < len(ref):\n",
    "                vtypes.append(DELETION)\n",
    "            else:\n",
    "                vtypes.append(SNV)\n",
    "        return \"-\".join(list(set(vtypes)))\n",
    "    else:  # regular alternative allele\n",
    "        if len(ref) < len(alt):\n",
    "            return INSERTION\n",
    "        elif len(alt) < len(ref):\n",
    "            return DELETION\n",
    "        return SNV\n",
    "\n",
    "\n",
    "def compute_distance(vpos: int, target_coord: int) -> int:\n",
    "    \"\"\"The function computes the distance between variant position and the \n",
    "    target start/stop coordinates.\n",
    "    \"\"\"\n",
    "    return vpos - target_coord\n",
    "\n",
    "\n",
    "def assign_flag(\n",
    "    vpos: int, target_start: int, target_stop: int, ref: str, alt: str, vtype: str\n",
    ") -> bool:\n",
    "    \"\"\"The function assesses if the edit occurred inside or outside the expected \n",
    "    target region. If the variant is a deletion or insertion the edit will be \n",
    "    flagged as TP if it overlaps the target position range.\n",
    "    \"\"\"\n",
    "    if vpos >= target_start and vpos <= target_stop:\n",
    "        return \"TP\"\n",
    "    else:\n",
    "        if \",\" in alt:  # polyploid allele\n",
    "            if INSERTION in vtype or DELETION in vtype:\n",
    "                for aa in alt.split(\",\"):\n",
    "                    if len(aa) < len(ref):  # deletion:\n",
    "                        padpos = list(range(vpos, vpos + len(ref)))\n",
    "                        if any([p <= target_stop and p >= target_start for p in padpos]):\n",
    "                            return \"TP\"\n",
    "                    if len(ref) < len(aa):  # insertion\n",
    "                        padpos = list(range(vpos, vpos + len(aa)))\n",
    "                        if any([p <= target_stop and p >= target_start for p in padpos]):\n",
    "                            return \"TP\"\n",
    "        else:\n",
    "            if DELETION in vtype:\n",
    "                padpos = list(range(vpos, vpos + len(ref)))\n",
    "                if any([p <= target_stop and p >= target_start for p in padpos]):\n",
    "                    return \"TP\"\n",
    "            elif INSERTION in vtype:\n",
    "                padpos = list(range(vpos, vpos + len(alt)))\n",
    "                if any([p <= target_stop and p >= target_start for p in padpos]):\n",
    "                    return \"TP\"\n",
    "    return \"FP\"\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On-regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_mutect2(exp_type: str, guide: str, cell_type: str) -> None:\n",
    "    \"\"\"The function build a TSV file listing the edits called by Mutect2.\"\"\"\n",
    "    # parse target files\n",
    "    if exp_type == \"circleseq\":\n",
    "        targets = pd.read_csv(\n",
    "            os.path.join(CIRCLESEQ, f\"{guide}.circleseq.hg19.hg38.targetname\"), sep=\"\\t\"\n",
    "        )\n",
    "        # column renaming for later join\n",
    "        columns = targets.columns.tolist()\n",
    "        targets.columns = columns[:-1] + [\"SITE\"]\n",
    "        tqdm.pandas()\n",
    "        edits = targets.progress_apply(\n",
    "            lambda x : read_mutect2(\n",
    "                os.path.join(\n",
    "                    EDITS, \n",
    "                    \"mutect2\", \n",
    "                    exp_type, \n",
    "                    cell_type, \n",
    "                    \"onregion\", \n",
    "                    guide,\n",
    "                    f\"{x[-1]}.{x[0]}:{int(x[1]) - PADSIZE}-{int(x[2]) + PADSIZE}.vcf.filtered.vcf\"\n",
    "                )\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "    else:  # exp_type == \"guideseq\"\n",
    "        targets = pd.read_csv(\n",
    "            os.path.join(GUIDESEQ, f\"{guide}.guideseq\"), sep=\"\\t\"\n",
    "        )\n",
    "        # column renaming for later join\n",
    "        columns = targets.columns.tolist()\n",
    "        targets.columns = columns[:6] + [\"SITE\"] + columns[7:]\n",
    "        tqdm.pandas()\n",
    "        edits = targets.progress_apply(\n",
    "            lambda x : read_mutect2(\n",
    "                os.path.join(\n",
    "                    EDITS, \n",
    "                    \"mutect2\", \n",
    "                    exp_type, \n",
    "                    cell_type, \n",
    "                    \"onregion\", \n",
    "                    guide,\n",
    "                    f\"{x[6]}.{x[0]}:{int(x[1]) - PADSIZE}-{int(x[2]) + PADSIZE}.vcf.filtered.vcf\"\n",
    "                )\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "    # build variants dataset\n",
    "    edits = parse_variants(edits, targets.SITE.tolist())\n",
    "    # assign variant type (SNP/indel)\n",
    "    edits[\"TYPE\"] = edits.apply(lambda x : assign_vtype(x[4], x[5]), axis=1)\n",
    "    # join targets and edits datasets\n",
    "    edits = edits.merge(targets, on=\"SITE\")\n",
    "    # keep columns of interest\n",
    "    if exp_type == \"circleseq\":\n",
    "        keep = [\n",
    "            \"SITE\", \"CHROM\", \"POS\", \"REF\", \"ALT\", \"FILTER\", \"TYPE\", \"Start\", \"End\", \"Strand\", \"Distance\"\n",
    "        ]\n",
    "    else:  # exp_type == \"guideseq\"\n",
    "        keep = [\n",
    "            \"SITE\", \"CHROM\", \"POS\", \"REF\", \"ALT\", \"FILTER\", \"TYPE\", \"start\", \"end\", \"Strand\", \"Mismatch Total\"\n",
    "        ]\n",
    "    edits = edits[keep]\n",
    "    edits.columns = [\n",
    "        \"SITE\", \"CHROM\", \"VAR-POS\", \"REF\", \"ALT\", \"FILTER\", \"TYPE\", \"TARGET-START\", \"TARGET-STOP\", \"STRAND\", \"MISMATCHES\"\n",
    "    ]  # rename columns\n",
    "    # computes distance between edits and expected edit sites\n",
    "    edits[\"START-DISTANCE\"] = edits.apply(\n",
    "        lambda x : compute_distance(int(x[2]), int(x[7])), axis=1\n",
    "    )\n",
    "    edits[\"STOP-DISTANCE\"] = edits.apply(\n",
    "        lambda x : compute_distance(int(x[2]), int(x[8])), axis=1\n",
    "    )\n",
    "    # assess if edits occurred inside or outside the expected target site\n",
    "    edits[\"FLAG\"] = edits.apply(\n",
    "        lambda x : assign_flag(int(x[2]), int(x[7]), int(x[8]), x[3], x[4], x[6]), \n",
    "        axis=1\n",
    "    )\n",
    "    # write the report\n",
    "    outfile = f\"mutect2_{exp_type}_{cell_type}_{guide}_onregion.tsv\"\n",
    "    edits.to_csv(\n",
    "        os.path.join(REPORTS, \"mutect2\", exp_type, cell_type, \"onregion\", guide, outfile),\n",
    "        sep=\"\\t\",\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:01<00:00, 142.66it/s]\n",
      "100%|██████████| 1043/1043 [00:06<00:00, 170.66it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 169.11it/s]\n",
      "100%|██████████| 1242/1242 [00:07<00:00, 170.44it/s]\n",
      "100%|██████████| 158/158 [00:00<00:00, 945.31it/s]\n",
      "100%|██████████| 1043/1043 [00:05<00:00, 173.87it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 163.96it/s]\n",
      "100%|██████████| 1242/1242 [00:07<00:00, 174.70it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 146.27it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 162.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.27it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 164.75it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 1227.93it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 177.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.68it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 184.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# construct datasets\n",
    "for experiment in EXPERIMENTS:\n",
    "    for cell_type in CELLTYPES:\n",
    "        for guide in GUIDES:\n",
    "            build_dataset_mutect2(experiment, guide, cell_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Off-regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_mutect2(exp_type: str, guide: str, cell_type: str) -> None:\n",
    "    \"\"\"The function build a TSV file listing the edits called by Mutect2.\"\"\"\n",
    "    # parse target files\n",
    "    if exp_type == \"circleseq\":\n",
    "        targets = pd.read_csv(\n",
    "            os.path.join(CIRCLESEQ, f\"{guide}.circleseq.hg19.hg38.targetname\"), sep=\"\\t\"\n",
    "        )\n",
    "        # column renaming for later join\n",
    "        columns = targets.columns.tolist()\n",
    "        targets.columns = columns[:-1] + [\"SITE\"]\n",
    "        tqdm.pandas()\n",
    "        edits = targets.progress_apply(\n",
    "            lambda x : read_mutect2(\n",
    "                os.path.join(\n",
    "                    EDITS, \n",
    "                    \"mutect2\", \n",
    "                    exp_type, \n",
    "                    cell_type, \n",
    "                    \"offregion\", \n",
    "                    guide,\n",
    "                    f\"{x[-1]}.{x[0]}:{int(x[1]) - 100 - PADSIZE}-{int(x[1]) - 100}.vcf.filtered.vcf\"\n",
    "                )\n",
    "            ),\n",
    "            axis=1\n",
    "        ) + targets.progress_apply(\n",
    "            lambda x : read_mutect2(\n",
    "                os.path.join(\n",
    "                    EDITS, \n",
    "                    \"mutect2\", \n",
    "                    exp_type, \n",
    "                    cell_type, \n",
    "                    \"offregion\", \n",
    "                    guide,\n",
    "                    f\"{x[-1]}.{x[0]}:{int(x[2]) + 100}-{int(x[2]) + 100 + PADSIZE}.vcf.filtered.vcf\"\n",
    "                )\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "    else:  # exp_type == \"guideseq\"\n",
    "        targets = pd.read_csv(\n",
    "            os.path.join(GUIDESEQ, f\"{guide}.guideseq\"), sep=\"\\t\"\n",
    "        )\n",
    "        # column renaming for later join\n",
    "        columns = targets.columns.tolist()\n",
    "        targets.columns = columns[:6] + [\"SITE\"] + columns[7:]\n",
    "        tqdm.pandas()\n",
    "        edits = targets.progress_apply(\n",
    "            lambda x : read_mutect2(\n",
    "                os.path.join(\n",
    "                    EDITS, \n",
    "                    \"mutect2\", \n",
    "                    exp_type, \n",
    "                    cell_type, \n",
    "                    \"offregion\", \n",
    "                    guide,\n",
    "                    f\"{x[6]}.{x[0]}:{int(x[1]) - 100 - PADSIZE}-{int(x[1]) - 100}.vcf.filtered.vcf\"\n",
    "                )\n",
    "            ),\n",
    "            axis=1\n",
    "        ) + targets.progress_apply(\n",
    "            lambda x : read_mutect2(\n",
    "                os.path.join(\n",
    "                    EDITS, \n",
    "                    \"mutect2\", \n",
    "                    exp_type, \n",
    "                    cell_type, \n",
    "                    \"offregion\", \n",
    "                    guide,\n",
    "                    f\"{x[6]}.{x[0]}:{int(x[2]) + 100}-{int(x[2]) + 100 + PADSIZE}.vcf.filtered.vcf\"\n",
    "                )\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "    # build variants dataset\n",
    "    edits = parse_variants(edits, targets.SITE.tolist())\n",
    "    # assign variant type (SNP/indel)\n",
    "    edits[\"TYPE\"] = edits.apply(lambda x : assign_vtype(x[4], x[5]), axis=1)\n",
    "    # join targets and edits datasets\n",
    "    edits = edits.merge(targets, on=\"SITE\")\n",
    "    # keep columns of interest\n",
    "    if exp_type == \"circleseq\":\n",
    "        keep = [\n",
    "            \"SITE\", \"CHROM\", \"POS\", \"REF\", \"ALT\", \"FILTER\", \"TYPE\", \"Start\", \"End\", \"Strand\", \"Distance\"\n",
    "        ]\n",
    "    else:  # exp_type == \"guideseq\"\n",
    "        keep = [\n",
    "            \"SITE\", \"CHROM\", \"POS\", \"REF\", \"ALT\", \"FILTER\", \"TYPE\", \"start\", \"end\", \"Strand\", \"Mismatch Total\"\n",
    "        ]\n",
    "    edits = edits[keep]\n",
    "    edits.columns = [\n",
    "        \"SITE\", \"CHROM\", \"VAR-POS\", \"REF\", \"ALT\", \"FILTER\", \"TYPE\", \"TARGET-START\", \"TARGET-STOP\", \"STRAND\", \"MISMATCHES\"\n",
    "    ]  # rename columns\n",
    "    # computes distance between edits and expected edit sites\n",
    "    edits[\"START-DISTANCE\"] = edits.apply(\n",
    "        lambda x : compute_distance(int(x[2]), int(x[7])), axis=1\n",
    "    )\n",
    "    edits[\"STOP-DISTANCE\"] = edits.apply(\n",
    "        lambda x : compute_distance(int(x[2]), int(x[8])), axis=1\n",
    "    )\n",
    "    # assess if edits occurred inside or outside the expected target site\n",
    "    edits[\"FLAG\"] = edits.apply(\n",
    "        lambda x : assign_flag(int(x[2]), int(x[7]), int(x[8]), x[3], x[4], x[6]), \n",
    "        axis=1\n",
    "    )\n",
    "    assert all([flag == \"FP\" for flag in edits.FLAG.tolist()])\n",
    "    # write the report\n",
    "    outfile = f\"mutect2_{exp_type}_{cell_type}_{guide}_offregion.tsv\"\n",
    "    edits.to_csv(\n",
    "        os.path.join(REPORTS, \"mutect2\", exp_type, cell_type, \"offregion\", guide, outfile),\n",
    "        sep=\"\\t\",\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:00<00:00, 178.17it/s]\n",
      "100%|██████████| 158/158 [00:00<00:00, 170.62it/s]\n",
      "100%|██████████| 1043/1043 [00:05<00:00, 178.96it/s]\n",
      "100%|██████████| 1043/1043 [00:05<00:00, 184.08it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 176.70it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 176.44it/s]\n",
      "100%|██████████| 1242/1242 [00:06<00:00, 183.89it/s]\n",
      "100%|██████████| 1242/1242 [00:06<00:00, 179.39it/s]\n",
      "100%|██████████| 158/158 [00:00<00:00, 167.41it/s]\n",
      "100%|██████████| 158/158 [00:00<00:00, 185.53it/s]\n",
      "100%|██████████| 1043/1043 [00:05<00:00, 177.55it/s]\n",
      "100%|██████████| 1043/1043 [00:05<00:00, 181.39it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 174.70it/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 188.20it/s]\n",
      "100%|██████████| 1242/1242 [00:07<00:00, 169.11it/s]\n",
      "100%|██████████| 1242/1242 [00:06<00:00, 180.97it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 159.55it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 184.98it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 172.45it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 192.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 200.23it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 190.21it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 188.12it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 179.00it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 197.06it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 191.53it/s]\n",
      "100%|██████████| 134/134 [00:00<00:00, 196.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 661.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 697.08it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 178.72it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 189.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# construct datasets\n",
    "for experiment in EXPERIMENTS:\n",
    "    for cell_type in CELLTYPES:\n",
    "        for guide in GUIDES:\n",
    "            build_dataset_mutect2(experiment, guide, cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f73eaaf9de625146a482694e21229ba12196d788f19574da510501605fc9bf9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
